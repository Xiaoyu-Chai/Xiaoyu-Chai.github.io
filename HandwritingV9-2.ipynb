{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HandwritingV9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtSHlZDFU0Dv"
      },
      "source": [
        "18-100 Lab 9: Machine Learning\n",
        "\n",
        "This lab is the starter code for the Machine Learning Lab. Please read through it to get a general understanding of what it does. But, you don't need to write any code, unless you want to. \n",
        "\n",
        "Instead, once you have a sense as to what the code is doing, you can focus your attention on parameterizing the neural network and training process. To do this, you probably want to focus on the section labelled, \"These parameters control some parameters of the neural network and its training\".\n",
        "\n",
        "Please see the lab write up for more detail.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nICyoycT0924",
        "outputId": "954a488f-2836-4319-db11-e94372a5da53"
      },
      "source": [
        "# This needs to be done once for each newly connected/allocated session. \n",
        "# It can be skipped after that via \"Runtime-->Run [beginning with and] after\"\n",
        "# Or, it can be commented in and out, as needed. \n",
        "\n",
        "# Install required libraries\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "!pip install tensorflowjs \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZujv_FV15xS"
      },
      "source": [
        "# These parameters control different aspects of the neural network and its training\n",
        "\n",
        "# These are the parameters you most likely want to explore\n",
        "TRAIN_SIZE=5000                 # This is the total pool of examples presentable to the network for training\n",
        "BATCH_SIZE=5                  # This is the total number of examples the network should look at before making adjustments\n",
        "EPOCHS=20                     # This is the number of epochs, i.e. batches of the training set\n",
        "\n",
        "HIDDEN_LAYERS=2               # The number of densely hidden layers within the neural network \n",
        "HIDDEN_LAYER_SIZE=128         # The number of neurons in each dense layer. For simplicity, each dense layer is set up to be the same\n",
        "\n",
        "LEARNING_RATE_COEFF=1.0\n",
        "      # Control the rate at which adjustments to weights are made: <1 slows, 1 is default, and >1 exaggerates\n",
        "\n",
        "# Feel free to change this, if you'd like, but doing so may not be particularly illuminating for this lab\n",
        "TEST_SIZE=100                 # This is the number of never-seen-before images used to evaluate the performance after training is complete. Do not lower this number to improve your results. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eihlnyacDUU"
      },
      "source": [
        "# Imports to bring in libraries we need and sometimes give them shorthand aliases \n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.modeling\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from google.colab import files\n",
        "\n",
        "# Load the TensorBoard notebook extension so we can visualize the netowrk and its training\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-06AoVJcPSB"
      },
      "source": [
        "# load data\n",
        "# This uses a method, e.g. code, provided with the data set\n",
        "# It automatically loads both training and validation <image, label> tuples\n",
        "(training_images, training_labels), (validation_images, validation_labels) = mnist.load_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FrOnSRAvxJz"
      },
      "source": [
        "# This limits the amount of data we use from each of the training and test sets to \n",
        "# the amount requested by the parameters provided for you to edit.\n",
        "\n",
        "training_images = training_images[0:TRAIN_SIZE]\n",
        "training_labels = training_labels[0:TRAIN_SIZE]\n",
        "validation_images = validation_images[0:TEST_SIZE]\n",
        "validation_labels = validation_labels[0:TEST_SIZE]\n",
        "\n",
        "print (training_images.shape)\n",
        "print (validation_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsHVcQ255p1l"
      },
      "source": [
        "# This shows us an example of what an image lookes like\n",
        "plt.figure()                                 # Create a new empty figure\n",
        "plt.imshow(training_images[0])               # Load the image into the figure\n",
        "plt.colorbar()                               # Add a color bar to the right of the figure to show the range of colors\n",
        "plt.grid(False)                              # Don't draw a graph paper -like grid\n",
        "plt.show()                                   # Display the image on the screen \n",
        "print (\"Label: \" + str(training_labels[0]))  # Put a text caption on the image to show its given \"ground truth\" label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0HHL1vccqtl"
      },
      "source": [
        "# Normalize inputs from 0-255 to 0.0-1.0\n",
        "# In other words divide every pixel by 255 so the range is from 0-1 instead of 0-255\n",
        "# This is because the neural netowrk expects inputs to be in the range from 0-1\n",
        "training_images = training_images / 255\n",
        "validation_images = validation_images / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsBXZkSLFQeT"
      },
      "source": [
        "# Goes through the same process as above to redisplay the image. \n",
        "# Note that the color bar is now 0.0-1.0\n",
        "plt.figure()\n",
        "plt.imshow(training_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "print (\"Label: \" + str(training_labels[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V07opLpfczQk"
      },
      "source": [
        "# Convert numerical labels to \"One-Hot Encoding\"\n",
        "# This means we encode each category's values as a separate boolean output variable\n",
        "# So,instead of having one output encoded as 0:0/255, 1:1/255, 2:2/255, etc, \n",
        "# each category gets a different output, so for example, consider 0, 1, and 2:\n",
        "# 0: {1, 0, 0}\n",
        "# 1: {0, 1, 0}\n",
        "# 2: {0, 0, 1} \n",
        "# This is important to do because There is no numerical relationship between the \n",
        "# categories. In other word, a 1.5 wouldn't mean half \"1\" and half \"2\". It would\n",
        "# just be hard to interpret and not good for training. \n",
        "number_of_classes = 10\n",
        "training_labels = np_utils.to_categorical(training_labels, number_of_classes)\n",
        "validation_labels = np_utils.to_categorical(validation_labels, number_of_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F9xR10Pc4uM"
      },
      "source": [
        "# Define the architecture of the neural network model\n",
        "\n",
        "# Define the model sequentially, layer by layer\n",
        "model = Sequential()\n",
        "\n",
        "# Add input layer, flattening out the 28x28 2D image into a 1D vector on its way into the network\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add hidden layer(s)\n",
        "# A dense layer is trhe basic fully connected later. \n",
        "# \"relu\" is a \"rectified linear unit\", which is a long way of saying it makes anything negative into a 0\n",
        "# There isn't such a thing as a negative color, so inhibition (negative weight) isn't likely to be helpful.\n",
        "for dense_layer in range (HIDDEN_LAYERS):\n",
        "  model.add(Dense(HIDDEN_LAYER_SIZE, activation='relu'))\n",
        "\n",
        "# Add output layer\n",
        "# The output layer is \"softmax\", which basically means that it takes the \n",
        "# various outputs and makes them sum up to 1.0, so that they can be interpreted sort of like probabilities\n",
        "# rather than us having to look at the whole set to interpret how much stronger or weaker one output is than others\n",
        "model.add(Dense(number_of_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m9uxcN1c9dU"
      },
      "source": [
        "# Compile model\n",
        "# This is, in some ways, like compiling a program. It takes the model above from a definiton to a usable instance\n",
        "\n",
        "# Categorical cross-entropy is a way of measuring error in situations where, as is the case with one-hot encoding, outputs are boolean and indicate membership in a single category\n",
        "# The \"adam\" optimizer is a form of gradient descent, i.e. a way for the network to assign blame for error and adjust weights by back propogation\n",
        "# Accuracy is a metric that measures the correctness of the categorization\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUm-g3UJ76WW"
      },
      "source": [
        "# Create a log directory where the neural network can store data for later visualization by TensorBoard\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Set up \"callback\" so that model.fit feeds data into the log diretory for TensorBoard as it trains\n",
        "# Note that this initializes the callback with the log directory created above and will log with each epoch, i.e. histogram_freq = 1\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZJ9bSpfdD1Q"
      },
      "source": [
        "# Fit, a.k.a. train, the model\n",
        "\n",
        "def custom_learning_rate(epoch, lrate):\n",
        "\treturn LEARNING_RATE_COEFF*lrate\n",
        " \n",
        "lrs_callback = LearningRateScheduler(custom_learning_rate)\n",
        "model.fit(training_images, training_labels, validation_data=(validation_images, validation_labels), epochs=EPOCHS, shuffle=True, batch_size=BATCH_SIZE, callbacks=[tensorboard_callback,lrs_callback])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9vObT9i84wC"
      },
      "source": [
        "# Start TensorBoard so we can visualize how the training unfolded\n",
        "# Be patient. You may have a blank window for up to 1-2 minutes (or, possibly more) while the TensorBoard processes the log files and prepares the visualizations\n",
        "# Set \"Smoothing\" to 0.0 so that you see the data. \n",
        "# Fee free to uncheck old runs (or run the cell that comes later to delete them)\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55maDe7GdMk-"
      },
      "source": [
        "# Get the final validation loss and accuracy as a simple \"score\", so you know how you did\n",
        "metrics = model.evaluate(validation_images, validation_labels, verbose=0)\n",
        "print(\"Metrics(Test loss & Test Accuracy): \")\n",
        "print(metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS-nx1tddHZ-"
      },
      "source": [
        "# Save the model so it can be used again without needing to retrain\n",
        "model.save('handwriting.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opG5Pxqxgzex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad96c5c8-10ef-47d8-887a-dea3d4d81142"
      },
      "source": [
        "# Convert model for use via a Web page.\n",
        "!mkdir model                                                          # Make a directory for the model, it is okay to ignore the error if it already exists\n",
        "!tensorflowjs_converter --input_format keras handwriting.h5 model/    # Convert the model and put it into the directory"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘model’: File exists\n",
            "2020-12-13 11:43:26.698513: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOW1xAD8haCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa69d2ef-306b-4f1a-d6dd-12de163cd57b"
      },
      "source": [
        "# Archive the model directory into a .zip file for easy downloading\n",
        "# Uncomment this when instructed in the lab handout. \n",
        "!zip -r handwriting.zip model "
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: model/ (stored 0%)\n",
            "updating: model/group1-shard1of1.bin (deflated 7%)\n",
            "updating: model/model.json (deflated 74%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaBLqg-rhLpx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "917f030f-e4a5-4054-d397-d5e4e45cfb8d"
      },
      "source": [
        "# Uncomment the lines below to download the .zip archive of the model from co-lab onto own computer for eventual upload to Web page. \n",
        "from google.colab import files\n",
        "files.download('handwriting.zip')"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e33c3080-56aa-4919-bb13-d757895dabc7\", \"handwriting.zip\", 440243)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq5x1wTm_ei0"
      },
      "source": [
        "# Uncomment the line below and run this cell if you'd like to delete all of your existing tensor flow logs.\n",
        "#!rm -rf ./logs/\n",
        "\n",
        "# You can also modify the line above to delete only certain logs by adding the date-stamped subdirectory using the date-stamp from TensorBoard, e.g. \n",
        "# !rm -rf ./logs/fit/20201123-023901/train/                   # Training logs from a particular run   \n",
        "# !rm -rf ./logs/fit/20201123-023901/validation/              # Validation logs from a particular run\n",
        "# !rm -rf ./logs/fit/20201123-023901/                         # Both training and validation logs from a particular run"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvNoNikuckCb"
      },
      "source": [
        "CREDITS:\n",
        "\n",
        "The code below is based upon the following blog:\n",
        "\n",
        "*   https://blog.tanka.la/2018/05/27/handwritten-digit-prediction-using-convolutional-neural-networks-in-tensorflow-with-keras-and-live-example-using-tensorflow-js/\n",
        "\n",
        "\n",
        "It was updated to save and download models as shown here:\n",
        "\n",
        "*   https://blog.tensorflow.org/2018/07/train-model-in-tfkeras-with-colab-and-run-in-browser-tensorflowjs.html\n",
        "\n",
        "And, inspired by the link below, updated to show metrics for underfit and overfit: \n",
        "*   https://www.tensorflow.org/tutorials/keras/overfit_and_underfit\n",
        "\n",
        "Those metrics, however, were ultimately implemented with TensorBoard based upon the link below: \n",
        "*   https://www.tensorflow.org/tensorboard/get_started\n",
        "\n",
        "The architecture was also simplified to be more accessible based upon this:\n",
        "*   https://www.tensorflow.org/tutorials/keras/classification\n"
      ]
    }
  ]
}